{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statistics-exam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-m3ZIWXLoh5"
      },
      "source": [
        "# Problem 1 [Done]\n",
        "\n",
        "Let a sequence of random variables converge in distribution to a constant. Does it converge in probability? If yes, prove it. If not, give an example.\n",
        "\n",
        "$$x_n \\leadsto x \\Longrightarrow \\mathbb{P}(|x_n - x| \\geqslant \\varepsilon) = \n",
        "\\mathbb{P}(x_n \\geqslant x + \\varepsilon) + \n",
        "\\mathbb{P}(x_n \\leqslant x - \\varepsilon) =$$\n",
        "$$= 1 - \\mathbb{P}(x_n < x + \\varepsilon) + \\mathbb{P}(x_n \\leqslant x - \\varepsilon) \\to \n",
        "1 - \\mathbb{P}(x < x + \\varepsilon) + \\mathbb{P}(x \\leqslant x - \\varepsilon) = 1 - 1 + 0 = 0 \n",
        "\\Longrightarrow x_n \\to x$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUnUba-PLrXS"
      },
      "source": [
        "# Problem 2 [Done]\n",
        "\n",
        "Let $x_1, x_2, \\dots, x_n$ be a sequence of random variables such that $\\mathbb{P}(x_n = 1/n) = 1 - 1/n$ and $\\mathbb{P}(x_n = n) = 1/n$. \n",
        "Does $x_n$ converge in probability?\n",
        "\n",
        "It can be seen that $\\forall n > 1 / \\varepsilon$ the definition of convergence in probability is satisfied\n",
        "\n",
        "$$\\mathbb{P}(|x_n| \\geqslant \\varepsilon) = \\mathbb{P}(x_n \\geqslant \\varepsilon) = 1/n \\to 0 \\Longrightarrow x_n \\to 0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO-FP9XqOmkz"
      },
      "source": [
        "# Problem 3 [Done]\n",
        "\n",
        "Can a biased (for any sample size) estimator be consistent? If yes, give an example. If not, prove it.\n",
        "\n",
        "Let $x_n$ be an estimator for $0$ such that $\\mathbb{P}(x_n = 0) = 1 - 1/n$ and $\\mathbb{P}(x_n = n) = 1/n$, then it is consistent\n",
        "\n",
        "$$\\mathbb{P}(|x_n| \\geqslant \\varepsilon) = \\mathbb{P}(x_n \\geqslant \\varepsilon) = 1/n \\to 0$$\n",
        "\n",
        "but biased for any sample size\n",
        "\n",
        "$$\\forall n: \\mathbb{E}x_n = 1 \\neq 0$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCxC0MKXlZ5"
      },
      "source": [
        "# Problem 4 [Done]\n",
        "\n",
        "Consider the problem of estimation the mean, where noise r.v. are i.i.d., have zero mean and finite variance. \n",
        "* Which of the following estimators are asymptotically normal for any noise distribution?\n",
        "\n",
        "Let us denote $\\mathbb{E}x_n = \\mu$. Then, sample mean is asymptotically normal estimator for sure\n",
        "$$\\mathbb{E}\\overline{x}_n = \\mu,\\;\n",
        "\\mathbb{D}\\overline{x}_n = \\frac{\\mathbb{D}x_n}{n} \\Longrightarrow \\sigma(\\overline{x}_n) = \\sqrt{\\mathbb{D}x_n} < \\infty$$\n",
        "$$\\frac{\\overline{x}_n\\sqrt{n}}{\\sqrt{\\mathbb{D}x_n}} \\leadsto \\text{N}_{0, 1}$$\n",
        "\n",
        "Sample median is not asymptotically normal estimator of variance in case of shifted exponential distribution\n",
        "$y = -1/\\lambda + x$, where $x \\sim \\text{E}_{\\lambda}$, since it is not even consistent (limits are not equal)\n",
        "\n",
        "$$F_y^{-1}(1/2) = -1/\\lambda + \\frac{\\log{2}}{\\lambda} \\neq \\mathbb{E}y = 0$$\n",
        "\n",
        "As for mean of the first and last order sample statistics, I just believe that there is also an example when such estimator is not \n",
        "asymptotically normal, but can not come up with it\n",
        "\n",
        "* Which of them will have smaller variance if noise is normally distributed? Sample mean, since it is MLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuMo_uDtPmGY"
      },
      "source": [
        "# Problem 5 [Done]\n",
        "\n",
        "Consider the asymptotically normal estimator obtained from a large i.i.d. sample of size $n$. \n",
        "Imagine that you need to improve the precision of an estimator by approximately $5$ times. \n",
        "How many additional samples should you add to the dataset (as a function of $n$)?\n",
        "\n",
        "An estimator $\\theta_n$ is asymptotically normal if\n",
        "\n",
        "$$\\frac{\\theta_n - \\theta}{\\sigma(\\theta_n) / \\sqrt{n}} \\leadsto \\text{N}_{0, 1}$$\n",
        "\n",
        "for some $\\sigma(\\theta_n)$. Here the variance of such estimator is\n",
        "\n",
        "$$\\sigma^2(\\theta_n)/n$$\n",
        "\n",
        "In order to make the error $5$ times smaller we need to reduce variance by $25$ times adding $24n$ more samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuXATNPJRj2w"
      },
      "source": [
        "# Problem 6 [Done]\n",
        "\n",
        "Consider confidence intervals for the parameter of a Bernoulli distribution. Compare the one derived based on Hoeffding inequality and the one based on asymptotic normality (see Lecture 4). Which one will you choose for the sample size n = 10. Explain your choice.\n",
        "\n",
        "The length of normal interval is\n",
        "\n",
        "$$2\\cdot z_{1 - \\alpha/2}\\sqrt{\\frac{p_n (1 - p_n)}{n}}$$\n",
        "\n",
        "while the length of Hoeffding interval is\n",
        "\n",
        "$$2\\cdot \\sqrt{\\frac{\\log(2 / \\alpha)}{2n}}$$\n",
        "\n",
        "We need to compare these values â€” after simplifying this we obtain\n",
        "\n",
        "$$z_{1 - \\alpha/2}^2 p_n (1 - p_n) \\leqslant \\frac{z_{1 - \\alpha/2}^2}{4} \\leqslant \\frac{\\log(2 / \\alpha)}{2}$$\n",
        "\n",
        "So the normal interval is preferable because it is shorter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OhHGEV2Li8X"
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx35xESrT3x0"
      },
      "source": [
        "alphas = np.linspace(0.01, 0.99)\n",
        "result = True\n",
        "\n",
        "for alpha in alphas:\n",
        "    result *= stats.norm.ppf(1 - alpha / 2) ** 2 / 4 <= np.log(2 / alpha) / 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYchPYkjUHVb",
        "outputId": "0a8c9926-b3a8-459e-ad03-22cbcbf06439"
      },
      "source": [
        "result"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYufrRPdUicF"
      },
      "source": [
        "# Problem 7 [Done]\n",
        "\n",
        "Consider a random sample of size $n$ from a very large population. The question is to find what proportion $p \\in [0,1]$ of people in the population have a certain opinion (it was yes/no question). The proportion in the sample who have the opinion is $f = 1/3$. How large must $n$ be so that the width of the confidence interval is guaranteed to be no larger than $0.01$? You may use normal interval.\n",
        "\n",
        "So we need to find $n$ such that\n",
        "\n",
        "$$2\\cdot z_{1 - \\alpha/2}\\sqrt{\\frac{p_n (1 - p_n)}{n}} < 0.01$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYJAiQX_UMLP"
      },
      "source": [
        "alpha = 0.05\n",
        "length = 0.01\n",
        "p = 1 / 3\n",
        "n = p * (1 - p) / (length / 2 / stats.norm.ppf(1 - alpha / 2)) ** 2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYMXuy3lV2qp",
        "outputId": "a6f8782f-f13a-4a05-ef85-4c542b728edb"
      },
      "source": [
        "np.ceil(n)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34147.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRN1wGIBWDdT"
      },
      "source": [
        "# Problem 8 [Done]\n",
        "\n",
        "Let $\\theta_n$ be asymptotically normal MLE of $\\theta$ for some parametrization $\\Theta$. Suppose, $\\tau$ is a function mapping $\\Theta$ \n",
        "to some set $\\Psi$.\n",
        "\n",
        "* Is $\\tau(\\theta_n)$ is an asymptotically normal estimator of $\\tau(\\theta)$ if $\\tau$ is a continously differentiable \n",
        "function? Yes, by theorem about delta-method\n",
        "\n",
        "* Is $\\tau(\\theta_n)$ is an MLE of $\\tau(\\theta)$ if $\\tau$ is a bijection? Yes, by theorem about equivariance of MLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Bhso9QXcOx"
      },
      "source": [
        "# Problem 9 [Done]\n",
        "\n",
        "Imagine that you use bootstrap to estimate the variance of some statistic. It appears that an estimate of variance by bootstrap has high variance itself. What should you do to improve the quality of the interval? Why?\n",
        "\n",
        "Maybe increase the number of bootstrap subsamples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmbSBwdGX4xy"
      },
      "source": [
        "# Problem 10 [Done]\n",
        "\n",
        "Let $x_1, x_2, \\dots, x_n$ be a sample from standard Cauchy distribution with location parameter $\\theta$. Consider a hypothesis testing \n",
        "problem $H_0: \\theta = \\theta_0$ against alternative $H_1: \\theta \\neq \\theta_0$. Which statistic should you base your criterion on? \n",
        "Suggest a criterion for testing a hypothesis. You may assume large sample size.\n",
        "\n",
        "Since Cauchy distribution has no mean (the corresponding Lebesgue integral does not converge), we can use median. In such case, the \n",
        "following statistic has asymptotically standard normal distribution (here $f$ is density function of Cauchy distribution)\n",
        "\n",
        "$$m_n = x_{[n/2]},\\;\\sigma^2(m_n) = \\frac{1}{4nf(m)^2} \\Longrightarrow T(x_1, x_2, \\dots, x_n) = \n",
        "\\frac{m_n - m}{\\sigma(m_n)} \\leadsto \\text{N}_{0, 1}$$\n",
        "\n",
        "<!-- $$\\mathbb{P}\\bigg[\\theta \\in C_n = \\Big(m_n - z_{1 - \\alpha/2}\\sigma(m_n), m_n + z_{1 - \\alpha/2}\\sigma(m_n)\\Big)\\bigg] \\to 1 - \\alpha$$ -->\n",
        "\n",
        "Thus, we reject $H_0$ with significance level $\\alpha$ if observe $|T(x_1, x_2, \\dots, x_n)| \\geqslant z_{1 - \\alpha/2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNbRX4UlaJeP"
      },
      "source": [
        "# Problem 11 [Done]\n",
        "\n",
        "Prove that $p$-value is uniformly distributed under the null hypothesis. Assume that the null hypothesis consists only of one \n",
        "continuous distribution. Why large $p$-value can not be a measure of confidence in $H_0$?\n",
        "\n",
        "We can express $p$-value as $1 - \\gamma$, where $\\gamma = F_T\\Big[T(x_1, x_2, \\dots, x_n)\\Big]$ under the null hypothesis $T \\sim F_T$, and use \n",
        "method of inverse transform\n",
        "\n",
        "$$F_{\\gamma}(x) = \\mathbb{P}(\\gamma < x) = \\mathbb{P}\\Big[F_T\\Big[T(x_1, x_2, \\dots, x_n)\\Big] < x\\Big] = \n",
        "\\mathbb{P}\\Big[T(x_1, x_2, \\dots, x_n) < F_T^{-1}(x)\\Big] = F_T\\Big[F_T^{-1}(x)\\Big] = x$$\n",
        "\n",
        "Since $\\gamma \\sim \\text{U}_{0, 1}$, the same is true for $p$-value $\\sim F_p$\n",
        "\n",
        "$$F_p(x) = \\mathbb{P}(1 - \\gamma < x) = 1 - \\mathbb{P}(\\gamma < 1 - x) = 1 - (1 - x) = x$$\n",
        "\n",
        "Big $p$-values may not only support the null hypothesis but also can be caused by the lack of data. That is why $p$-value \n",
        "can not be the measure of confidence in $H_0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cBYsDasV25_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}